#!/usr/bin/env python
# FAST-iCLIP

import os, cmath, math, sys, glob, subprocess, re, argparse, shutil, datetime, csv
import numpy as np
from matplotlib_venn import venn2
import pandas as pd
from collections import defaultdict
from operator import itemgetter
import matplotlib as mpl
import matplotlib.pyplot as plt
from optparse import OptionParser
mpl.rcParams['savefig.dpi'] = 2 * mpl.rcParams['savefig.dpi']
mpl.rcParams['path.simplify'] = True
csv.register_dialect("textdialect",delimiter='\t')

global sampleName
global outfilepath
global logFile
global logOpen

### Checking environment variables ###
home = os.environ.get("FASTICLIP_PATH")
if not home and glob.glob("docs/"):
	home = os.getcwd()
if not home:
	print "Error: Environment variable FASTICLIP_PATH not found. Please set it to the FAST-iCLIP installation directory."
	exit()
if not glob.glob(home + "/docs/"):
	print "Error: docs folder not inside FASTICLIP_PATH. Make sure this environment variable is set correctly, or \
	that you have run ./configure inside the installation directory."
	exit()

### Parsing arguments ###

parser = argparse.ArgumentParser(description="FAST-iCLIP: a pipeline to process iCLIP data", epilog="Example: fasticlip -i rawdata/example_MMhur_R1.fastq rawdata/example_MMhur_R2.fastq --mm9 -n MMhur -o results")
parser.add_argument('-i', metavar='INPUT', nargs='+', help="Up to 4 input fastq or fastq.gz files separated by a space", required=True)
parser.add_argument('--trimmed', action='store_true', help="flag if files are already trimmed")
group = parser.add_mutually_exclusive_group()
group.add_argument('--hg19', action='store_true', help="required if your CLIP is from human")
group.add_argument('--mm9', action='store_true', help="required if your CLIP is from mouse")
parser.add_argument('-n', metavar='NAME', help="Name of output directory", required=True)
parser.add_argument('-o', metavar='OUTPUT', help="Name of directory where output directory will be made", required=True)
parser.add_argument('-f', metavar='N', type=int, help="First base to keep on 5' end of each read. Default is 14.", default=14)
parser.add_argument('-a', metavar='ADAPTER', help="3' adapter to trim from the end of each read. Default is AGATCGGAAGAGCGGTTCAGCAGGAATGCCGAGACCGATCTCGTATGCCGTCTTCTGCTTG.", default='AGATCGGAAGAGCGGTTCAGCAGGAATGCCGAGACCGATCTCGTATGCCGTCTTCTGCTTG')
parser.add_argument('-tr', metavar='REPEAT_THRESHOLD_RULE', type=str, help="m,n: at least m samples must each have at least n RT stops mapped to repeat RNAs. Default is 1,4 (1 sample); 2,3 (2 samples); x,2 (x>2 samples)")
parser.add_argument('-tn', metavar='NONREPEAT_THRESHOLD_RULE', type=str, help="m,n: at least m samples must each have at least n RT stops mapped to nonrepeat RNAs. Default is 1,4 (1 sample); 2,3 (2 samples); x,2 (x>2 samples)")
parser.add_argument('-m', metavar='MAPQ', type=int, help="Minimum MAPQ (Bowtie alignment) score allowed. Default is 42.", default=42)
parser.add_argument('-q', metavar='Q', type=int, help="Minimum average quality score allowed during read filtering. Default is 25.", default=25)
parser.add_argument('-p', metavar='P', type=int, help="Percentage of bases that must have quality > q during read filtering. Default is 80.", default=80)
parser.add_argument('-l', metavar='L', type=int, help="Minimum length of read. Default is 15.", default=15)


# organism
args = parser.parse_args()
if not (args.hg19 or args.mm9):
	print "Error: must include --hg19 or --mm9. Exiting."
	exit()
if args.hg19: org = 'human' 
else: org = 'mouse'

# input files
reads = args.i
for fn in reads:
	if not glob.glob(fn):
		print "Error: input file " + fn + " not accessible. Exiting."
		exit()
		
# sample name and output directory
sampleName = args.n
outfilepath = args.o
if not glob.glob(outfilepath):
	print "Error: output directory " + outfilepath + " not accessible. Exiting."
	exit()
outfilepath = outfilepath + '/%s/'%sampleName
if not glob.glob(outfilepath): os.system("mkdir " + outfilepath)

# Create log and start pipeline
logFile=outfilepath + "runLog"
logOpen=open(logFile, 'w')


### Parameters ###
iCLIP3pBarcode = args.a # Barcode sequence to trim from reads.
mapq = args.m # Minimum MAPQ score allowed
q = args.q # Minimum quality score to keep during filtering.
p = args.p # Percentage of bases that must have quality > q during filtering.
l = args.l +  args.f - 1 # Minimum length of read + 5' adapter
iCLIP5pBasesToTrim=args.f # Number of reads to trim from 5' end of clip reads + 1 (this number represents the first base kept)
k = '1' # k=N distinct, valid alignments for each read in bt2 mapping.
expand = 15 # Bases to expand around RT position after RT stops are merged.
CLIPPERoutNameDelim = '_' # Delimiter that for splitting gene name in the CLIPper windows file.

nsamp = len(reads)
if not args.tn:
	if nsamp == 1: threshold_nr = 4
	elif nsamp == 2: threshold_nr = 3
	else: threshold_nr = 2
	minpass_nr = 0
else:
	try: [minpass_nr, threshold_nr] = [int(x) for x in args.tn.split(',')]
	except: 
		print "Nonrepeat threshold rule must be in form m,n where m,n are integers"
		exit()
	minpass_nr = min(minpass_nr, nsamp) 

if not args.tr:
	if nsamp == 1: threshold_rep = 4
	elif nsamp == 2: threshold_rep = 3
	else: threshold_rep = 2
	minpass_rep = 0
else:
	try: [minpass_rep, threshold_rep] = [int(x) for x in args.tr.split(',')]
	except: 
		print "Repeat threshold rule must be in form m,n where m,n are integers."
		exit()
	minpass_rep = min(minpass_rep, nsamp) 

if org == 'human':
	repeat_index=home + '/docs/hg19/repeat/rep_spaced' # bt2 index for repeat RNA.
	repeatGenomeBuild=home+'/docs/hg19/repeat/repeatRNA_spaced.fa' # Sequence of repeat index.
	repeatAnnotation=home+'/docs/hg19/repeat/Hs_repeatIndex_spaced_positions.txt' # Repeat annotation file.
	start18s=3657
	end18s=5527
	start5s=6623
	end5s=6779
	start28s=7935
	end28s=12969
	rRNAend=13314
	index=home + '/docs/hg19/hg19/hg19' # bt2 index for mapping.
	index_tag='hg19' # Name of bt2 index.
	genomeFile=home+'/docs/hg19/human.hg19.genome' # Genome file for bedGraph, etc.
	genomeForCLIPper='-shg19' # Parameter for CLIPper.
	blacklistregions=home+'/docs/hg19/wgEncodeDukeMapabilityRegionsExcludable.bed' # Blacklist masker.
	repeatregions=home+'/docs/hg19/repeat_masker.bed' # Repeat masker.
	geneAnnot=glob.glob(home+'/docs/hg19/genes_types/*') # List of genes by type.
	snoRNAmasker=home+'/docs/hg19/snoRNA_reference/snoRNAmasker_formatted_5pExtend.bed' # snoRNA masker file.
	miRNAmasker=home+'/docs/hg19/miR_sort_clean.bed' # miRNA masker file.
	fivePUTRBed=home+'/docs/hg19/5pUTRs_Ensbl_sort_clean_uniq.bed' # UTR annotation file.
	threePUTRBed=home+'/docs/hg19/3pUTRs_Ensbl_sort_clean_uniq.bed' # UTR annotation file.
	exonBed=home+'/docs/hg19/Exons_Ensbl_sort_clean_uniq.bed' # UTR annotation file.
	utrFile=home+'/docs/hg19/hg19_ensembl_UTR_annotation.txt' # UTR annotation file.
	genesFile=home+'/docs/hg19/hg19_ensembl_genes.txt' # Gene annotation file.
	sizesFile=home+'/docs/hg19/hg19.sizes' # Genome sizes file. 
	snoRNAindex=home+'/docs/hg19/snoRNA_reference/sno_coordinates_hg19_formatted.bed' # snoRNA coordinate file.
	tRNAindex=home+'/docs/hg19/trna/tRNA_hg19'
	geneStartStopRepo=home+'/docs/hg19/all_genes.txt'
elif org == 'mouse':
	repeat_index=home + '/docs/mm9/repeat/rep_spaced' # bt2 index for repeat RNA.
	repeatGenomeBuild=home+'/docs/mm9/repeat/Mm_repeatRNA_spaced.fa' # Sequence of repeat index.
	repeatAnnotation=home+'/docs/mm9/repeat/Mm_repeatIndex_spaced_positions.txt' # Repeat annotation file.
	start18s=4007
	end18s=5876
	start5s=6877
	end5s=7033
	start28s=8123
	end28s=12836
	rRNAend=13401
	index=home + '/docs/mm9/mm9/mm9' # bt2 index for mapping.
	index_tag='mm9' # Name of bt2 index.
	genomeFile=home+'/docs/mm9/mm9.sizes' # Genome file for bedGraph, etc.
	genomeForCLIPper='-smm9' # Parameter for CLIPper.
	blacklistregions=home+'/docs/mm9/mm9-blacklist.bed' # Blacklist masker.
	repeatregions=home+'/docs/mm9/Mm_mm9_repeatMasker_formatted.bed' # Repeat masker.
	geneAnnot=glob.glob(home+'/docs/mm9/genes_types/*') # List of genes by type. 
	snoRNAmasker=home+'/docs/mm9/snoRNA_reference/mm9_snoRNAmasker_formatted_5pExtend.bed' # snoRNA masker file.
	miRNAmasker=home+'/docs/mm9/mm9_miRNA.bed' # miRNA masker file.
	fivePUTRBed=home+'/docs/mm9/mm9_5pUTR.bed' # UTR annotation file.
	threePUTRBed=home+'/docs/mm9/mm9_3pUTR.bed' # UTR annotation file. 
	exonBed=home+'/docs/mm9/mm9_exons.bed' # UTR annotation file. 
	utrFile=home+'/docs/mm9/mm9_ensembl_UTR_annotation.txt' # UTR annotation file. 
	genesFile=home+'/docs/mm9/mm9_ensembl_genes.txt' # Gene annotation file. 
	sizesFile=home+'/docs/mm9/mm9.sizes' # Genome sizes file. 
	snoRNAindex=home+'/docs/mm9/snoRNA_reference/mm9_sno_coordinates_formatted.bed' # snoRNA coordinate file. 
	tRNAindex=home+'/docs/mm9/tRNA/tRNA_mm9'
	geneStartStopRepo=home+'/docs/mm9/all_genes.txt'

### start running pipeline ###
now=datetime.datetime.now()
logOpen.write("Timestamp:%s\n"%str(now))
logOpen.write("\n###Parameters used###\n")
logOpen.write("3' barcode:%s\n'"%iCLIP3pBarcode)
logOpen.write("Minimum quality score (q):%s\n"%q)
logOpen.write("Percentage of bases with > q:%s\n"%p)
logOpen.write("5' bases to trim:%s\n'"%iCLIP5pBasesToTrim)
logOpen.write("k distinct, valid alignments for each read in bt2 mapping:%s\n"%k)
logOpen.write("Threshold for minimum number of RT stops (repeat): %s samples with >= %s RT stops\n"%(minpass_rep, threshold_rep))
logOpen.write("Threshold for minimum number of RT stops (nonrepeat): %s samples with >= %s RT stops\n"%(minpass_nr, threshold_nr))
logOpen.write("Bases for expansion around conserved RT stops:%s\n"%expand)
logOpen.write("\n\n\n")

print "Processing sample %s" %(sampleName)
logOpen.write("Processing sample: "+sampleName+'\n')

def remove_dup(reads, q, p):
	uniq_reads = []
	for inread in reads:
		outread = outfilepath + os.path.basename(inread)
		is_compressed = True if inread[-3:] == '.gz' else False
		if is_compressed:
			outread=outread.replace(".fastq.gz", "_nodup.fasta")		
		else:
			outread=outread.replace(".fastq", "_nodup.fasta")
			
		uniq_reads.append(outread)
		if glob.glob(outread):
			uniq_reads=uniq_reads+[outread]
			print "Filtering and duplicate removal already done."
			logOpen.write("Filtering and duplicate removal already done.\n")
			continue
			
		if is_compressed:
			cmd_1 = "gunzip -c {}".format(inread)
		else:
			cmd_1 = "cat {}".format(inread)
			
		cmd_2 = "fastq_quality_filter -Q33 -q{} -p{}".format(q, p)
		cmd_3 = "fastx_collapser -Q33 > {}".format(outread)
		full_cmd = ' | '.join([cmd_1, cmd_2, cmd_3])
		print full_cmd
		os.system(full_cmd)
	return uniq_reads

if not args.trimmed: 
	print "Removing duplicates"
	dup_removed_reads = remove_dup(reads, q, p)

def trim(reads, adapter3p, l, n):
	# Usage: Trims a specified number of bases from the 5' end of each read.
	# Input: List of fastq files.
	# Output: List of 5p trimmed files.
	program = home + "/bin/fasta_to_fastq.pl"
	trimmedReads = []
	for inread in reads:
		outread = inread.replace("_nodup.fasta", "_trimmed.fastq")
		trimmedReads.append(outread)
		if glob.glob(outread):
			print "5' and 3' barcode trimming already done."
			logOpen.write("5' and 3' barcode trimming already done.\n")
			continue
		
		cmd_1 = "perl {} {}".format(program, inread)
		cmd_2 = "fastx_clipper -n -l{} -Q33 -a {}".format(l, adapter3p)
		cmd_3 = "fastx_trimmer -f{} -Q33 > {}".format(n, outread)
		full_cmd = ' | '.join([cmd_1, cmd_2, cmd_3])
		print full_cmd
		os.system(full_cmd)
		logOpen.write("Perform 5' and 3' barcode trimming.\n")
	return trimmedReads

if not args.trimmed: 
	print "Trimming 5' and 3'"
	processed_reads = trim(dup_removed_reads, iCLIP3pBarcode, l, iCLIP5pBasesToTrim)
else: processed_reads = reads

def runBowtie(processed_reads, repeat_index, trna_index, genome_index):
	# Usage: Read mapping.
	# Input: Fastq files of replicate trimmed read files.
	# Output: Path to samfile for each read.

	rep_sam = []
	trna_sam = []
	genome_sam = []
	for infastq in processed_reads:
		rep_mapped = infastq.replace(".fastq", "_mappedToRepeat.sam")
		rep_mapped = outfilepath + os.path.basename(rep_mapped)
		rep_unmapped = infastq.replace(".fastq", "_notMappedToRepeat.fastq")
		rep_unmapped = outfilepath + os.path.basename(rep_unmapped)
		trna_mapped = rep_unmapped.replace("_notMappedToRepeat.fastq", "_mappedToTrna.sam")
		trna_unmapped = rep_unmapped.replace("_notMappedToRepeat.fastq", "_notMappedToTrna.fastq")
		genome_mapped = trna_unmapped.replace("_notMappedToTrna.fastq", "_mappedToGenome.sam")
		rep_sam.append(rep_mapped)
		trna_sam.append(trna_mapped)
		genome_sam.append(genome_mapped)

		if glob.glob(genome_mapped):
			print "Bowtie already done."
			logOpen.write("Bowtie already done.\n")
			continue
			
		cmd = "bowtie2 -p 8 -x {} {} --un {} -S {} > {} 2>&1".format(repeat_index, infastq, rep_unmapped, rep_mapped, rep_mapped + '_stats.txt')
		print cmd
		os.system(cmd)
		
		cmd = "bowtie2 -p 8 -x {} {} --un {} -S {} > {} 2>&1".format(trna_index, rep_unmapped, trna_unmapped, trna_mapped, trna_mapped + '_stats.txt')
		print cmd
		os.system(cmd)
		
		cmd = "bowtie2 -p 8 -x {} {} -S {} > {} 2>&1".format(genome_index, trna_unmapped, genome_mapped, genome_mapped + '_stats.txt')
		print cmd
		os.system(cmd)
		
		logOpen.write("Perform mapping.")
	return rep_sam, trna_sam, genome_sam

print "\nRun mapping to repeat index."  
(rep_sam, trna_sam, gen_sam) = runBowtie(processed_reads, repeat_index, tRNAindex, index)

def run_samtools(samfiles, mapq):
	# Usage: Samfile processing (also takes unique mappers only)
	# Input: Sam files from Bowtie mapping.
	# Output: Sorted bedFiles.
	program = 'samtools'
	program2 = 'bamToBed'
	out_bedfiles = []
	for samfile in samfiles:
		bamfile_sort = samfile.replace('.sam','_sorted') 
		bedfile = bamfile_sort.replace('_sorted', '_withDupes.bed') 
		out_bedfiles.append(bedfile)
			
		cmd_1 = "cat {} | samtools view -q {} -Suo - - | samtools sort - {}".format(samfile, mapq, bamfile_sort)
		cmd_2 = "bamToBed -i {} > {}".format(bamfile_sort + '.bam', bedfile)
		print cmd_1
		os.system(cmd_1)
		print cmd_2
		os.system(cmd_2)
		
	return out_bedfiles

print "\nRun samtools."
logOpen.write("Run samtools.\n")
rep_bed = run_samtools(rep_sam, mapq)
trna_bed = run_samtools(trna_sam, mapq)
gen_bed = run_samtools(gen_sam, mapq)

def remove_blacklist_retro(gen_bed, blacklistregions, repeatregions):
	# Usage: Remove repeat regions from bedfile following mapping.
	# Input: .bed file after mapping (duplicates removed by samtools) and blastlist regions removed.
	# Output: Bedfile with repeat regions removed.

	masked=[]
	for bedIn in gen_bed:
		no_blacklist = bedIn.replace('.bed', '_noBlacklist.bed')
		no_repeat = bedIn.replace('.bed', '_noRepeat.bed')
		repeat = bedIn.replace('.bed', '_repeat.bed')
			
		cmd_1 = "bedtools intersect -a {} -b {} -v -sorted > {}".format(bedIn, blacklistregions, no_blacklist)
		cmd_2 = "bedtools intersect -a {} -b {} -v -sorted -s > {}".format(no_blacklist, repeatregions, no_repeat)
		cmd_3 = "bedtools intersect -a {} -b {} -wb -sorted -s -f 0 > {}".format(no_blacklist, repeatregions, repeat)
		print cmd_1
		os.system(cmd_1)
		print cmd_2
		os.system(cmd_2)
		print cmd_3
		os.system(cmd_3)
		masked.append(no_repeat)
	return masked
	
print "\nRun repeat and blacklist region masker."
logOpen.write("Run repeat and blacklist masker.\n")
gen_norepeat_bed = remove_blacklist_retro(gen_bed, blacklistregions, repeatregions)

def separateStrands(mappedReads):
	# Usage: separate positive and negative strands.
	# Input: Paths to two bed files from Samtools.
	# Output: Paths to bed files isolated by strand.
	negativeStrand=[]
	positiveStrand=[]
	for mapFile in mappedReads:
		with open(mapFile, 'r') as infile:
			neg_strand=mapFile.replace('.bed','_neg.bed')
			pos_strand=mapFile.replace('.bed','_pos.bed')
			negativeStrand=negativeStrand+[neg_strand]
			positiveStrand=positiveStrand+[pos_strand]
				
			neg = open(neg_strand, 'w')
			pos = open(pos_strand, 'w')
			for line in infile:	
				if str(line.strip().split('\t')[5]) == '-':
					neg.write(line)
				elif str(line.strip().split('\t')[5]) == '+':
					pos.write(line)
	return (negativeStrand,positiveStrand)

def modifyNegativeStrand(negativeStrandReads):
	# Usage: For negative stranded reads, ensure 5' position (RT stop) is listed first.
	# Input: Bed file paths to all negative stranded.
	# Output: Paths to modified bed files.
	negativeStrandEdit=[]
	for negativeRead in negativeStrandReads:
		neg_strand_edited=negativeRead.replace('_neg.bed','_negEdit.bed')
		negativeStrandEdit=negativeStrandEdit+[neg_strand_edited]
		
		neg_edit = open(neg_strand_edited, 'w')
		with open(negativeRead, 'r') as infile:
			for line in infile:	
				chrom,start,end,name,quality,strand=line.strip().split('\t')
				neg_edit.write('\t'.join((chrom,end,str(int(end)+30),name,quality,strand))+'\n')
	return negativeStrandEdit

def isolate5prime(strandedReads):
	# Usage: Isolate only the Chr, 5' position (RT stop), and strand.
	# Input: Bed file paths to strand separated reads.
	# Output: Paths RT stop files.
	RTstops=[]
	for reads in strandedReads:
		RTstop=reads.replace('.bed','_RTstop.bed')
		with open(reads, 'r') as infile:
			RTstops=RTstops+[RTstop]
			
			f = open(RTstop, 'w')
			for line in infile:	
				chrom,start,end,name,quality,strand=line.strip().split('\t')
				f.write('\t'.join((chrom,start,strand))+'\n')
	return RTstops

def fileCat(destinationFile,fileList):
	f = open(destinationFile, "w")
	for tempfile in fileList:
		readfile = open(tempfile, "r")
		f.write(readfile.read())
		readfile.close()
	f.close()

def RTcounts(RTfile):
	posRT_R1=pd.DataFrame(pd.read_table(RTfile,index_col=None,header=None,sep='\t'))
	posRT_R1.columns=['Chr','Start','Strand']
	cts=posRT_R1.groupby(['Chr','Start']).size()
	return cts

def countPassed(x, n):
	ct = 0
	for i in x:
		if i >= n: ct += 1
	return ct
	
def mergeRT(RTstopFiles, outfilename, statsfilename, minpass, threshold, expand, strand):
	# Usage: Merge RT stops between replicates and keep only those positions that exceed threshold.
	# Input: Files with RT stops for each replicate, outfile, threshold, strand, and bases to expand around RT stop.
	# Output: None. Writes merged RT stop file.
	
	cts = [RTcounts(fn) for fn in RTstopFiles]
	m = pd.concat(cts, axis=1, join='inner')
	m['numpass'] = m.apply(lambda x: countPassed(x, threshold), axis=1)
	m = m[m['numpass'] >= minpass]
	m_filter = m.copy(deep=True)
	m_filter['sum'] = m.apply(sum, axis=1)
	m_filter['mean'] = m.apply(np.mean, axis=1)
	m_filter['stdev'] = m.apply(np.std, axis=1)
	
	f = open(outfilename, 'w')
	fs = open(statsfilename, 'w')
	for i in m_filter.index:
		chrom = i[0]
		RT = i[1]
		count = m_filter.loc[i,'sum']
		mean = m_filter.loc[i, 'mean']
		stdev = m_filter.loc[i, 'stdev']
		if RT > expand:
			read = '\t'.join((chrom, str(int(RT)-expand), str(int(RT)+expand), 'CLIPread', '255', strand))+'\n'
			sread = '\t'.join((chrom, str(int(RT)-expand), str(int(RT)+expand), 'CLIPread', '255', strand, mean, stdev))+'\n'
		else:
			read = '\t'.join((chrom,str(int(RT)), str(int(RT)+expand), 'CLIPread', '255', strand))+'\n'
			sread = '\t'.join((chrom,str(int(RT)), str(int(RT)+expand), 'CLIPread', '255', strand, mean, stdev))+'\n'
		f.write(read*(count))
		fs.write(sread)
	f.close()
	fs.close()

print "\nRepeat RT stop isolation."
logOpen.write("Repeat RT stop isolation.\n")
readsByStrand_rep=separateStrands(rep_bed)
negativeRTstop_rep=isolate5prime(modifyNegativeStrand(readsByStrand_rep[0])) 
positiveRTstop_rep=isolate5prime(readsByStrand_rep[1]) 

print "Merge Repeat RT stops."
logOpen.write("Merge Repeat RT stops.\n")
posMerged = outfilepath+sampleName+'_repeat_positivereads.mergedRT'
negMerged = outfilepath+sampleName+'_repeat_negativereads.mergedRT'
negAndPosMerged = outfilepath+sampleName+'_threshold=%s'%threshold_rep+'_repeat_allreads.mergedRT.bed'
mergeRT(positiveRTstop_rep, posMerged, posMerged + '_stats', minpass_rep, threshold_rep, expand, '+')
mergeRT(negativeRTstop_rep, negMerged, negMerged + '_stats', minpass_rep, threshold_rep, expand, '-')
fileCat(negAndPosMerged, [posMerged, negMerged])
fileCat(negAndPosMerged + '_stats', [posMerged + '_stats', negMerged + '_stats'])

print "Nonrepeat RT stop isolation."
logOpen.write("Nonrepeat RT stop isolation.\n")
readsByStrand = separateStrands(gen_norepeat_bed)
negativeRTstop = isolate5prime(modifyNegativeStrand(readsByStrand[0])) 
positiveRTstop = isolate5prime(readsByStrand[1]) 

print "Merge Nonrepeat RT stops."
logOpen.write("Merge Nonrepeat RT stops.\n")
posMerged = outfilepath+sampleName+'_%s_positivereads.mergedRT'%index_tag
negMerged = outfilepath+sampleName+'_%s_negativereads.mergedRT'%index_tag
negAndPosMerged = outfilepath+sampleName+'_threshold=%s'%threshold_nr+'_%s_allreads.mergedRT.bed'%index_tag
mergeRT(positiveRTstop, posMerged, posMerged + '_stats', minpass_nr, threshold_nr, expand, '+')
mergeRT(negativeRTstop, negMerged, negMerged + '_stats', minpass_nr, threshold_nr, expand, '-')
fileCat(negAndPosMerged,[posMerged,negMerged])
fileCat(negAndPosMerged + '_stats', [posMerged + '_stats', negMerged + '_stats'])


def runCLIPPER(RTclusterfile,genome,genomeFile):
	# Useage: Process the mergedRT file and pass through CLIPper FDR script.
	# Input: Merged RT file.
	# Output: CLIPper input (.bed) file and output file.
	program='bedToBam'
	program2='samtools'
	program3='bamToBed'
	program4='clipper'
	
	bamfile=RTclusterfile.replace('.bed','.bam')  
	outfh=open(bamfile, 'w')
	proc=subprocess.Popen([program,'-i',RTclusterfile,'-g',genomeFile],stdout=outfh)
	proc.communicate()
	
	bamfile_sort=bamfile.replace('.bam','.srt')
	proc2=subprocess.Popen([program2,'sort',bamfile,bamfile_sort])
	proc2.communicate()
	
	bamfile_sorted=bamfile_sort+'.bam'
	mapStats=bamfile_sorted.replace('.srt.bam','.mapStats.txt') 
	outfh=open(mapStats, 'w')
	proc3=subprocess.Popen([program2,'flagstat',bamfile_sorted],stdout=outfh)
	proc3.communicate()
	
	proc4=subprocess.Popen([program2,'index',bamfile_sorted])
	proc4.communicate()
	
	CLIPPERin=bamfile_sorted.replace('.srt.bam','_CLIPPERin.bed') 
	outfh=open(CLIPPERin, 'w')
	proc5=subprocess.Popen([program3,'-i',bamfile_sorted],stdout=outfh)
	proc5.communicate()
	
	CLIPPERout_dup=CLIPPERin.replace('_CLIPPERin.bed','_CLIP_clusters_dupl') 
	proc6=subprocess.Popen([program4,'--bam',bamfile_sorted,genome,'--outfile=%s'%CLIPPERout_dup],)
	proc6.communicate()
	outfh.close()
	
	# added by BD 4/12/15 to merge adjacent clip clusters and remove duplicates
	CLIPPERout=CLIPPERout_dup.replace('_CLIP_clusters_dupl','_CLIP_clusters') 
	ifile = open(CLIPPERout_dup,'r')
	reader = csv.reader(ifile, 'textdialect')
	ofile = open(CLIPPERout,'w')
	writer = csv.writer(ofile, 'textdialect')
	currRow = ['chr1',0,0,0,0,'+']
	for row in reader:
		currStart = int(currRow[1])
		currEnd = int(currRow[2])
		newStart = int(row[1])
		newEnd = int(row[2])
		if currStart==newStart and currEnd==newEnd: continue #duplicates
		if math.fabs(newStart-currEnd) <= 15 and currRow[5]==row[5]: #overlap and same strand
			if int(currRow[1]) != 0: #not the first one
				currRow[2]=newEnd #merge the two adjacent clusters
		else: #not overlap
			if int(currRow[1]) != 0:
				writer.writerow(currRow)
			currRow = row #cycle continues
	writer.writerow(currRow) #fencepost
	
	ifile.close()
	ofile.close()	
	
	return (CLIPPERin,CLIPPERout)

def modCLIPPERout(CLIPPERin,CLIPPERout):
	# Usage: Process the CLIPper output and isolate lowFDR reads based upon CLIPper windows.
	# Input: .bed file passed into CLIPper and the CLIPper windows file.
	# Output: Low FDR reads recovered using the CLIPer windows file, genes per cluster, gene list of CLIPper clusters, and CLIPper windows as .bed.
	program='intersectBed'
	CLIPperOutBed=CLIPPERout+'.bed'
	CLIPpeReadsPerCluster=CLIPPERout+'.readsPerCluster'
	CLIPpeGeneList=CLIPPERout+'.geneNames'
	f = open(CLIPperOutBed,'w')
	g = open(CLIPpeReadsPerCluster,'w')
	h = open(CLIPpeGeneList,'w')
	with open(CLIPPERout,'r') as infile:
		for line in infile:	
			try:
				# *** Old CLIPper includes a header that cannot be parsed. Handle this. ***
				# *** Old CLIPper: Ensembl genes are parsed with <name>_<cluster>_<count>. ***
				chrom,start,end,name,stats,strand,start_2,end_2 = line.strip().split('\t')
				readPerCluster=name.strip().split('_')[2]
				geneName=name.strip().split('_')[0].split('.')[0]
				f.write('\t'.join((chrom,start,end,name,stats,strand))+'\n')
				g.write((readPerCluster+'\n'))
				h.write((geneName+'\n'))
			except:
				print ""
	f.close()
	g.close()
	h.close()
	CLIPPERlowFDR=CLIPperOutBed.replace('.bed','_lowFDRreads.bed')
	outfh=open(CLIPPERlowFDR,'w')
	# Intersect input reads with the CLIPper windows and report full result for both.
	proc=subprocess.Popen([program,'-a',CLIPPERin,'-b',CLIPperOutBed,'-wa','-wb','-s'],stdout=outfh)
	proc.communicate()
	outfh.close()
	return (CLIPPERlowFDR,CLIPpeReadsPerCluster,CLIPpeGeneList,CLIPperOutBed)

print "Run CLIPper."
logOpen.write("Run CLIPper.\n")

CLIPPERio=runCLIPPER(negAndPosMerged,genomeForCLIPper,genomeFile)
CLIPPERin=CLIPPERio[0]
CLIPPERout=CLIPPERio[1]
clipperStats=modCLIPPERout(CLIPPERin,CLIPPERout)
CLIPPERlowFDR=clipperStats[0] # Low FDR reads returned filtered through CLIPper windows
CLIPpeReadsPerCluster=clipperStats[1] # Number of reads per CLIPper cluster
CLIPpeGeneList=clipperStats[2] # Gene names returned from the CLIPper file
CLIPperOutBed=clipperStats[3] # CLIPper windows as a bed file

def getBedCenterPoints(inBed):
	# Usage: Obtain center coordinates of bedFile.
	# Input: BedFile.
	# Output: Center coordinates returned.
	outBed=inBed.replace('.bed','_centerCoord.bed')	
	f=open(outBed, 'w')
	with open(inBed, 'r') as infile:
		for line in infile:	
			elementList=line.strip().split('\t')
			f.write('\t'.join((elementList[0],str(int(elementList[1])+expand),str(int(elementList[1])+expand+1),elementList[9],elementList[4],elementList[5],'\n')))
	f.close()
	return outBed

def cleanBedFile(inBed):
	# Usage: Sort and recover only first 6 fields from a bed file.
	# Input: BedFile.
	# Output: Sorted bedFile with correct number of fields.
	program='sortBed'
	CLIPperOutBed=inBed.replace('.bed','_cleaned.bed')	
	sortedBed=CLIPperOutBed.replace('_cleaned.bed','_cleaned_sorted.bed')
	f=open(CLIPperOutBed, 'w')
	with open(inBed, 'r') as infile:
		for line in infile:	
			elementList=line.strip().split('\t')
			f.write('\t'.join((elementList[0],elementList[1],elementList[2],elementList[3],elementList[4],elementList[5],'\n')))
	f.close()
	outfh=open(sortedBed, 'w')
	proc=subprocess.Popen([program, '-i', CLIPperOutBed],stdout=outfh)
	proc.communicate()
	outfh.close()
	return sortedBed

def makeBedGraph(lowFDRreads,sizesFile):
	# Usage: From a bedFile, generate a bedGraph and bigWig.
	# Input: BedFile.
	# Output: BedGraph file.
	program='genomeCoverageBed'
	program2=home + '/bin/bedGraphToBigWig'
	cleanBed=cleanBedFile(lowFDRreads)
	outname=cleanBed.replace('.bed','.bedgraph')
	outname2=cleanBed.replace('.bed','.bw')
	outfh=open(outname,'w')
	proc=subprocess.Popen([program,'-bg','-split','-i',cleanBed,'-g',sizesFile],stdout=outfh)
	proc.communicate()
	outfh2=open(outname2,'w')
	proc2=subprocess.Popen([program2,outname,sizesFile,outname2],stdout=subprocess.PIPE)
	proc2.communicate()
	return outname

print "Make bedGraph"
logOpen.write("Make bedGraph.\n")
bedGraphCLIPout=makeBedGraph(CLIPPERlowFDR,genomeFile)
CLIPPERlowFDRcenters=getBedCenterPoints(CLIPPERlowFDR)
allLowFDRCentersBedGraph=makeBedGraph(CLIPPERlowFDRcenters,genomeFile)

def filterSnoRNAs(proteinCodingReads,snoRNAmasker,miRNAmasker):
	# Usage: Filter snoRNA and miRNAs from protein coding reads.
	# Input: .bed file with protein coding reads.
	# Output: snoRNA and miR filtered .bed file.
	program='intersectBed'
	proteinWithoutsnoRNAs=proteinCodingReads.replace('.bed','_snoRNAremoved.bed')
	proteinWithoutmiRNAs=proteinWithoutsnoRNAs.replace('.bed','_miRNAremoved.bed')
	outfh=open(proteinWithoutsnoRNAs, 'w')
	proc=subprocess.Popen([program,'-a',proteinCodingReads,'-b',snoRNAmasker,'-v','-s'],stdout=outfh)
	proc.communicate()
	outfh.close()
	outfh=open(proteinWithoutmiRNAs, 'w')
	proc=subprocess.Popen([program,'-a',proteinWithoutsnoRNAs,'-b',miRNAmasker,'-v','-s'],stdout=outfh)
	proc.communicate()
	outfh.close()
	return (proteinWithoutmiRNAs)

def getLowFDRReadTypes(CLIPPERlowFDR,pathToGeneLists):
	# Usage: Given a list of genes, return all reads for the associated genes.
	# Input: Gene list and the path to lowFDR read file.
	# Output: List of reads assocaited with the given genes.
	lowFDRgenelist=[]
	for path in pathToGeneLists:
		outfile=path+'_LowFDRreads.bed'
		proc=subprocess.Popen('grep -F -f %s %s > %s'%(path,CLIPPERlowFDR,outfile),shell=True)
		proc.communicate()
		return_code=proc.wait() # *** Remove later. ***
		lowFDRgenelist=lowFDRgenelist+[outfile]
	return lowFDRgenelist

def compareLists(list1,list2,outname):
	# Usage: Compare gene lists and output matches to the file. 
	# Input: Two gene lists.
	# Output: Path file containing the matching genes.
	f=open(list1,'r')
	g=open(list2,'r')
	commonGenes=set(f.readlines()) & set(g.readlines())
	geneCategory=outname.split('.')[1]
	outputName=outfilepath+'clipGenes_'+geneCategory
	outfh=open(outputName,'w')
	for gene in commonGenes:
		outfh.write(gene)
	outfh.close()
	return outputName

def getLowFDRGeneTypes(CLIPpeGeneList,geneAnnot):
	# Usage: Get all genes listed under each type, compare to CLIPper targets.
	# Input: .bed file passed into CLIPper and the CLIPper windows file.
	# Output: Path to file containing all CLIPper genes of each type.
	geneTypes=[]
	for genepath in geneAnnot:
		lowFDRgenes=compareLists(CLIPpeGeneList,genepath,os.path.split(genepath)[1])
		geneTypes=geneTypes+[lowFDRgenes]
	return geneTypes

print "Partition reads by type."
logOpen.write("Partition reads by type.\n")

pathToGeneLists=getLowFDRGeneTypes(CLIPpeGeneList,geneAnnot)
pathToReadLists=getLowFDRReadTypes(CLIPPERlowFDR,pathToGeneLists)

proteinCodingReads=outfilepath+'clipGenes_proteinCoding_LowFDRreads.bed'
proteinBedGraph=makeBedGraph(proteinCodingReads,genomeFile)
filteredProteinCodingCenters=filterSnoRNAs(getBedCenterPoints(proteinCodingReads),snoRNAmasker,miRNAmasker)
filteredProteinCentersBedGraph=makeBedGraph(filteredProteinCodingCenters,genomeFile)

lincRNAReads=outfilepath+'clipGenes_lincRNA_LowFDRreads.bed'
filteredLincRNACenters=filterSnoRNAs(getBedCenterPoints(lincRNAReads),snoRNAmasker,miRNAmasker)


def sortFilteredBed(bedFile):
	bf=pd.DataFrame(pd.read_table(bedFile,header=None))
	bf.columns=['Chr','Start','Stop','CLIPper_name','Q','Strand']
	geneCounts=countHitsPerGene(bf)
	return geneCounts

def countHitsPerGene(bf):
	# *** THIS MAY DEPEND UPON THE VERSION OF CLIPPER USED ***
	bf['geneName']=bf['CLIPper_name'].apply(lambda x: x.split('_')[0])
	geneCounts=bf.groupby('geneName').size()
	geneCounts.sort(ascending=False)
	return geneCounts

def getSnoRNAreads(CLIPPERlowFDRcenters,snoRNAindex):
	program='intersectBed'		
	bedFile=outfilepath+'clipGenes_snoRNA_LowFDRreads.bed'
	outfh=open(bedFile, 'w')
	proc=subprocess.Popen([program,'-a',CLIPPERlowFDRcenters,'-b',snoRNAindex,'-s','-wa','-wb'],stdout=outfh)
	proc.communicate()
	outfh.close()	
	return bedFile

def countSnoRNAs(bedFile_sno):
	bf=pd.DataFrame(pd.read_table(bedFile_sno,header=None))
	bf.columns=['Chr','Start','End','CLIPper_name','Q','Strand','Chr_snoRNA','Start_snoRNA','Stop_snoRNA','name_snoRNA','Type','strand_snoRNA']
	geneCounts=bf.groupby('name_snoRNA').size()
	geneCounts.sort(ascending=False)
	return geneCounts

def countRemainingGeneTypes(remaining):
	for bedFile in remaining:
		try:
			bf=pd.DataFrame(pd.read_table(bedFile,header=None))
			bf.columns=['Chr','Start','End','ReadName','Q','Strand','CLIPper_winChr','CLIPper_winStart','CLIPper_winEmd','CLIPper_winaName','CLIPper_winP','CLIPper_winStrand']
			# *** THIS MAY DEPEND UPON THE VERSION OF CLIPPER USED ***
			bf['geneName']=bf['CLIPper_winaName'].apply(lambda x: x.split('_')[0])
			geneCounts=bf.groupby('geneName').size()
			geneCounts.sort(ascending=False) 
						
			head,fname=os.path.split(bedFile)
			geneType=fname.split("_")[1]
			outfilepathToSave=outfilepath+'/PlotData_ReadsPerGene_%s'%geneType
			geneCounts.to_csv(outfilepathToSave)
			
		except ValueError:
			print "No reads in %s"%bedFile

print "Generate sorted gene lists by gene type."
logOpen.write("Generate sorted gene lists by gene type.\n")

bedFile_pc=outfilepath+"clipGenes_proteinCoding_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved.bed"
geneCounts_pc=sortFilteredBed(bedFile_pc) 
outfilepathToSave=outfilepath + '/PlotData_ReadsPerGene_proteinCoding'
geneCounts_pc.to_csv(outfilepathToSave)

bedFile_linc=outfilepath+"clipGenes_lincRNA_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved.bed"
if os.stat(bedFile_linc).st_size > 0:
	geneCounts_linc=sortFilteredBed(bedFile_linc)
	outfilepathToSave=outfilepath + '/PlotData_ReadsPerGene_lincRNA'
	geneCounts_linc.to_csv(outfilepathToSave)

CLIPPERlowFDRcenters=getBedCenterPoints(CLIPPERlowFDR)
allLowFDRCentersBedGraph=makeBedGraph(CLIPPERlowFDRcenters,genomeFile)
bedFile_sno=getSnoRNAreads(CLIPPERlowFDRcenters,snoRNAindex)
if os.stat(bedFile_sno).st_size > 0:
	geneCounts_sno=countSnoRNAs(bedFile_sno) 
	outfilepathToSave=outfilepath + '/PlotData_ReadsPerGene_snoRNA'
	geneCounts_sno.to_csv(outfilepathToSave)
	
remaining=[f for f in glob.glob(outfilepath+"*_LowFDRreads.bed") if 'lincRNA' not in f and 'proteinCoding' not in f and 'snoRNA' not in f]
countRemainingGeneTypes(remaining)


def makeClusterCenter(windowsFile):
	# Usage: Generate a file of cluster centers.
	# Input: Raw CLIPper output file.
	# Output: File with coordinates for the center of each CLIPper cluster.
	cleanBed = cleanBedFile(windowsFile)
	centers=cleanBed.replace('.bed','.clusterCenter')
	f = open(centers, 'w')
	with open(cleanBed, 'r') as infile:
		for line in infile:
			elementList = line.strip().split('\t')
			diff=abs(int((int(elementList[1])-int(elementList[2]))/2))
			f.write(elementList[0]+'\t'+str(int(elementList[1])+diff)+'\t'+str(int(elementList[1])+diff+1)+'\n')
	f.close()
	return centers

def getClusterIntensity(bedGraph,centerCoordinates):
	# Usage: Generate a matrix of read itensity values around CLIPper cluster center.
	# Input: BedGraph and cluster center file.
	# Output: Generates a matrix, which is passed into R.
	program=home + '/bin/grep_chip-seq_intensity.pl'
	program2='wait'
	proc=subprocess.Popen(['perl',program, centerCoordinates, bedGraph],)
	proc.communicate()
	logOpen.write("Waiting for Cluster Intensity file completion...\n")
	proc2=subprocess.Popen(program2,shell=True)
	proc2.communicate()
	
print "Get binding intensity around cluster centers."
logOpen.write("Get binding intensity around cluster centers.\n")
bedGraphCLIPin=makeBedGraph(CLIPPERin,genomeFile)
centerCoordinates=makeClusterCenter(CLIPperOutBed) 
getClusterIntensity(bedGraphCLIPin,centerCoordinates)


def extract_regions(bedIn, fivePUTRBed, threePUTRBed, exonBed):
	# Usage: Extract all region specific reads from the input file.
	# Input: .bed files
	# Output: Mutually exclusive partitions of the input file.
	
	exonreads = bedIn.replace('.bed', '_exons.bed')
	intronreads = bedIn.replace('.bed', '_introns.bed')
	cmd1 = "bedtools intersect -a {} -b {} -s -u > {}".format(bedIn, exonBed, exonreads)
	cmd2 = "bedtools intersect -a {} -b {} -s -v > {}".format(bedIn, exonBed, intronreads)
	print "Exons"; os.system(cmd1)
	print "Introns"; os.system(cmd2)
	
	fivePreads = bedIn.replace('.bed', '_5p.bed')
	threePreads = bedIn.replace('.bed', '_3p.bed')
	cmd1 = "bedtools intersect -a {} -b {} -s -u > {}".format(exonreads, fivePUTRBed, fivePreads)
	cmd2 = "bedtools intersect -a {} -b {} -s -u > {}".format(exonreads, threePUTRBed, threePreads)
	print "5'"; os.system(cmd1)
	print "3'"; os.system(cmd2)
	
	cdsreads = bedIn.replace('.bed', '_cds.bed')
	cmd1 = "cat {} {} | bedtools intersect -a {} -b stdin -s -v > {}".format(fivePUTRBed, threePUTRBed, exonreads, cdsreads)
	print "CDS"; os.system(cmd1)
	
	return (exonreads, intronreads, fivePreads, threePreads, cdsreads)

def read_readspergene_file(data_dict, pos, fn):
	with open(fn, 'r') as ifile:
		for line in ifile:
			[gene, cts] = line.rstrip().split(',')
			data_dict[gene][pos] = int(cts)
	return data_dict
	
def gene_binding_by_region():
	fivePfile = outfilepath + '/PlotData_ReadsPerGene_5pUTR'
	threePfile = outfilepath + '/PlotData_ReadsPerGene_3pUTR'
	CDSfile = outfilepath + '/PlotData_ReadsPerGene_CDS'
	exonfile = outfilepath + '/PlotData_ReadsPerGene_Exons'
	intronfile = outfilepath + '/PlotData_ReadsPerGene_Introns'
	allfile = outfilepath + '/PlotData_ReadsPerGene_proteinCoding'
	
	gene_to_counts = defaultdict(lambda: [0,0,0,0,0,0])  # all, exon, intron, 5P, CDS, 3P
	if glob.glob(allfile):
		gene_to_counts = read_readspergene_file(gene_to_counts, 0, allfile)
	if glob.glob(exonfile):
		gene_to_counts = read_readspergene_file(gene_to_counts, 1, exonfile)
	if glob.glob(intronfile):
		gene_to_counts = read_readspergene_file(gene_to_counts, 2, intronfile)
	if glob.glob(fivePfile):
		gene_to_counts = read_readspergene_file(gene_to_counts, 3, fivePfile)
	if glob.glob(CDSfile):
		gene_to_counts = read_readspergene_file(gene_to_counts, 4, CDSfile)
	if glob.glob(threePfile):
		gene_to_counts = read_readspergene_file(gene_to_counts, 5, threePfile)
	
	ofn = outfilepath + '/PlotData_proteinCoding_byRegion'
	print ofn
	with open(ofn, 'w') as ofile:
		writer = csv.writer(ofile)
		writer.writerow(['Gene', 'All', 'Exonic', 'Intronic', '5P', 'CDS', '3P'])
		for gene in gene_to_counts:
			row = [gene]
			row.extend(gene_to_counts[gene])
			writer.writerow(row)
	
print "Intron and UTR analysis."
logOpen.write("Intron and UTR analysis.\n")
exonreads, intronreads, fivePreads, threePreads, cdsreads = extract_regions(filteredProteinCodingCenters, fivePUTRBed, threePUTRBed, exonBed)

if os.stat(fivePreads).st_size > 0:
	geneCounts_5p=sortFilteredBed(fivePreads) 
	outfilepathToSave=outfilepath+'/PlotData_ReadsPerGene_5pUTR'
	geneCounts_5p.to_csv(outfilepathToSave)

if os.stat(threePreads).st_size > 0:
	geneCounts_3p=sortFilteredBed(threePreads) 
	outfilepathToSave=outfilepath+'/PlotData_ReadsPerGene_3pUTR'
	geneCounts_3p.to_csv(outfilepathToSave)

if os.stat(cdsreads).st_size > 0:
	geneCounts_cds=sortFilteredBed(cdsreads) 
	outfilepathToSave=outfilepath+'/PlotData_ReadsPerGene_CDS'
	geneCounts_cds.to_csv(outfilepathToSave) 

if os.stat(exonreads).st_size > 0:
	geneCounts_5p=sortFilteredBed(exonreads) 
	outfilepathToSave=outfilepath+'/PlotData_ReadsPerGene_Exons'
	geneCounts_5p.to_csv(outfilepathToSave)

if os.stat(intronreads).st_size > 0:
	geneCounts_3p=sortFilteredBed(intronreads) 
	outfilepathToSave=outfilepath+'/PlotData_ReadsPerGene_Introns'
	geneCounts_3p.to_csv(outfilepathToSave)

gene_binding_by_region()

def makeTab(bedGraph,genesFile,sizesFile):
	program = home + '/bin/bedGraph2tab.pl'
	program2 = 'wait'
	outfile=bedGraph.replace('.bedgraph','.tab')
	if glob.glob(outfile): return outfile
	proc = subprocess.Popen(['perl',program,genesFile,sizesFile,bedGraph,outfile],)
	proc.communicate()
	proc2 = subprocess.Popen(program2,shell=True)
	proc2.communicate()
	return outfile

def makeAvgGraph(bedGraph,utrFile,genesFile,sizesFile):
	# Usage: Generate a matrix of read intensity values across gene body.
	# Input: BedGraph.
	# Output: Generates two matrices.
	program= home + '/bin/averageGraph_scaled_tab.pl'
	program2 = 'wait'
	tabFile=makeTab(bedGraph,genesFile,sizesFile)
	outhandle=tabFile.replace('.tab','_UTRs')
	proc = subprocess.Popen(['perl',program,utrFile,tabFile,tabFile,outhandle],)
	proc.communicate()
	proc2 = subprocess.Popen(program2,shell=True)
	proc2.communicate()

print "Gene body analysis."
logOpen.write("Gene body analysis.\n")
bedGraphProtein=makeBedGraph(bedFile_pc,genomeFile)
makeAvgGraph(bedGraphProtein,utrFile,genesFile,sizesFile)


def getGeneStartStop(bedFile,geneRef):
	try:
		bf=pd.DataFrame(pd.read_table(bedFile,header=None))
		bf.columns=['Chr','Start','End','ReadName','Q','Strand','CLIPper_winChr','CLIPper_winStart','CLIPper_winEmd','CLIPper_winaName','CLIPper_winP','CLIPper_winStrand']
		bf['geneName']=bf['CLIPper_winaName'].apply(lambda x: x.split('_')[0].split('.')[0])
		merge=pd.merge(geneRef,bf,left_on='Ensembl Gene ID',right_on='geneName')
		ncRNA_startStop=merge[['Ensembl Gene ID','Gene Start (bp)','Gene End (bp)','Start','End','Strand']]
		outfilepathToSave=bedFile.replace(".bed",".geneStartStop")
		ncRNA_startStop.to_csv(outfilepathToSave)
	except ValueError:
		print "No reads in %s"%bedFile

print "ncRNA gene body analysis."
geneRef=pd.DataFrame(pd.read_table(geneStartStopRepo))
remaining=[f for f in glob.glob(outfilepath+"*_LowFDRreads.bed") if 'lincRNA' not in f and 'proteinCoding' not in f and 'snoRNA' not in f]
for bedFile in remaining:
	st_stop=getGeneStartStop(bedFile,geneRef)


# lincRNA file processing
bedFile_linc=outfilepath+"clipGenes_lincRNA_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved.bed"
if os.stat(bedFile_linc).st_size > 0:
	bf=pd.DataFrame(pd.read_table(bedFile_linc,header=None))
	bf.columns=['Chr','Start','Stop','CLIPper_name','Q','Strand']
	bf['geneName']=bf['CLIPper_name'].apply(lambda x: x.split('_')[0])
	merge=pd.merge(geneRef,bf,left_on='Ensembl Gene ID',right_on='geneName')
	ncRNA_startStop=merge[['Ensembl Gene ID','Gene Start (bp)','Gene End (bp)','Start','Stop','Strand']]
	outfilepathToSave=bedFile_linc.replace(".bed",".geneStartStop")
	ncRNA_startStop.to_csv(outfilepathToSave)


def makeRepeatAnnotation(repeatGenomeBuild,repeatAnnotation):
	repeat_genome=np.genfromtxt(repeatGenomeBuild,dtype='string')
	repeat_genome_bases=repeat_genome[1]
	repeat_genome_size=len(repeat_genome[1])
	repeatAnnotDF=pd.DataFrame(pd.read_table(repeatAnnotation,header=None))
	repeatAnnotDF.columns=['Name','Length','IndexStart','IndexEnd']
	repeatAnnotDF['End_for_extraction']=repeatAnnotDF['IndexEnd']+1 # Python list extraction is not end index inclusive; to extract sequence, use end + 1. 
	return (repeat_genome_bases,repeatAnnotDF)


print "Record repeat RNA."
repeat_genome_bases,repeatAnnotDF=makeRepeatAnnotation(repeatGenomeBuild,repeatAnnotation)
repeatAnnotDF.set_index('Name',inplace=True,drop=False)
# Get merged data for repeat index.
repeatMerged=glob.glob(outfilepath+"*repeat_allreads.mergedRT.bed")
rep=pd.read_table(repeatMerged[0],dtype=str,header=None)
rep.columns=['Rep_index','Start','Stop','Read_name','Q','Strand']
rep['RT_stop']=rep['Start'].astype(int)+expand
for ix in repeatAnnotDF.index:
	end=repeatAnnotDF.loc[ix,'IndexEnd']
	repName=repeatAnnotDF.loc[ix,'Name']
	gene_hits=rep[(rep['RT_stop']<int(repeatAnnotDF.loc[ix,'IndexEnd']))&(rep['RT_stop']>int(repeatAnnotDF.loc[ix,'IndexStart']))]
	gene_hits['Repeat_End']=repeatAnnotDF.loc[ix,'IndexEnd']
	gene_hits['Repeat_Start']=repeatAnnotDF.loc[ix,'IndexStart']
	outfilepathToSave=outfilepath + '/PlotData_RepeatRNAreads_%s'%repName
	gene_hits.to_csv(outfilepathToSave)

#%matplotlib inline
import matplotlib
import commands
matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']

def lineCount(filename):
	print filename
	if filename[-3:] == '.gz':
		cmd_1 = "gunzip -c {}".format(filename)
	else:
		cmd_1 = "cat {}".format(filename)
	cmd = cmd_1 + ' | wc -l'
	return int(commands.getstatusoutput(cmd)[1])

def plot_ReadAccounting(outfilepath,sampleName):

	bases = [os.path.splitext(os.path.basename(reads[i]))[0] for i in range(nsamp)]
	bases = [base.replace('.fastq.gz', '').replace('.fastq', '') for base in bases]
	bases = [outfilepath + base for base in bases]
	
	filesToCount = reads
	filesToCount.extend([base + '_trimmed.fastq' for base in bases])
	filesToCount.extend([base + '_trimmed_mappedToRepeat_withDupes.bed' for base in bases])
	filesToCount.extend([base + '_trimmed_mappedToTrna_withDupes.bed' for base in bases])
	filesToCount.extend([base + '_trimmed_mappedToGenome_withDupes.bed' for base in bases])
	filesToCount.extend([base + '_trimmed_mappedToGenome_withDupes_noRepeat.bed' for base in bases])
	
	clipperIN = outfilepath+sampleName+'_threshold=%s_%s_allreads.mergedRT_CLIPPERin.bed'%(threshold_nr,index_tag)
	clipperOUT = outfilepath+sampleName+'_threshold=%s_%s_allreads.mergedRT_CLIP_clusters_lowFDRreads.bed'%(threshold_nr,index_tag)
	filesToCount.extend([clipperIN, clipperOUT])
	
	fileNameBases = ['Raw', 'No dupes', 'Repeat Mapped', 'tRNA Mapped', 'Genome Mapped', 'Blacklist Masked']
	fileNames = [b + " (R{})".format(i + 1) for b in fileNameBases for i in range(nsamp)]
	fileNames.extend(['ClipperIn', 'ClipperOut'])
	
	counts = []
	counter = 0
	for fileString in filesToCount:
		temp = lineCount(fileString)
		if counter < 4:
			temp = temp/4 # Fastq files
		counts = counts+[temp]
		counter += 1

	ind = np.arange(len(counts)) + 0.5
	plt.barh(ind,list(reversed(np.log10(np.array(counts)))),align='center',color='blue')
	plt.xlabel('log10(Counts per file)',fontsize=5)
	locs,pltlabels = plt.xticks(fontsize=5)
	plt.setp(pltlabels, rotation=90, fontsize=5)
	plt.yticks(ind,list(reversed(fileNames)),fontsize=5)
	plt.tick_params(axis='yticks',labelsize=5) 
	ax=plt.gca()
	for line in ax.get_yticklines():
		line.set_markersize(0)
	plt.title('Read counts',fontsize=5)
	
	print fileNames
	print counts
	readDF=pd.DataFrame()
	outfilepathToSave=outfilepath + '/PlotData_ReadsPerPipeFile'
	readDF.to_csv(outfilepathToSave)

print "Making Figure 1"
logOpen.write("Making Figure 1\n")

def plot_BoundGeneTypes(outfilepath,sampleName):
	record=pd.DataFrame()   
	# Exclude specific files (e.g., UTR-specific reads).
	geneListToPlot=[f for f in glob.glob(outfilepath+'PlotData_ReadsPerGene_*') if '5pUTR' not in f and '3pUTR' not in f and 'CDS' not in f]
	for boundGenes in geneListToPlot:
		glist=pd.read_csv(boundGenes,header=None)
		glist.columns=['GeneName','Count']
		gName=boundGenes.split('_')[-1]
		record.loc[gName,'genesBound']=glist.shape[0]
		record.loc[gName,'totalReads']=glist['Count'].sum()
	record.sort('genesBound',inplace=True)
	outfilepathToSave=outfilepath + '/PlotData_ReadAndGeneCountsPerGenetype'
	record.to_csv(outfilepathToSave)
	ind = np.arange(record.shape[0]) + 0.5
	plt.bar(ind,record['genesBound'],align='center',color='blue')
	locs,pltlabels = plt.yticks(fontsize=5)
	locs,pltlabels = plt.xticks(ind,record.index,fontsize=5)
	plt.setp(pltlabels, rotation=90, fontsize=5)
	plt.tick_params(axis='xticks',labelsize=5) 
	ax=plt.gca()
	for line in ax.get_xticklines():
		line.set_markersize(0)
	plt.ylabel('Number of genes bound',fontsize=5)
	plt.tick_params(axis='yticks',labelsize=5)
	plt.title('Bound genes by class',fontsize=5)
	

def plot_ReadsPerCluster(outfilepath,sampleName):
	readPerCluster=outfilepath+sampleName+'_threshold=%s_%s_allreads.mergedRT_CLIP_clusters.readsPerCluster'%(threshold_nr,index_tag)
	clust=pd.DataFrame(pd.read_table(readPerCluster,header=None))
	clust.columns=['ReadsPerCluster']
	clust=clust['ReadsPerCluster']
	interval=10
	bins=range(min(clust)-10,max(clust)+10,interval)
	hist,bins=np.histogram(clust,bins=bins)
	width=0.7*(bins[1]-bins[0]) 
	center=(bins[:-1] + bins[1:])/2 
	plt.bar(center, hist,align='center',width=width)
	locs,pltlabels = plt.yticks(fontsize=5)
	locs,pltlabels = plt.xticks(center,center,fontsize=5)
	plt.setp(pltlabels, rotation=90, fontsize=3.5)
	plt.tick_params(axis='yticks',labelsize=5) 
	plt.xlabel('Reads per cluster (bin=%s)'%interval,fontsize=5)
	plt.ylabel('Frequency (RT stop count)',fontsize=5)
	plt.title('Reads per cluster',fontsize=5)
	plt.xlim(0,100) # Make the histogram easy to view.
	# plt.xlim(-interval,np.max(center)+interval)
	

def plot_ClusterSizes(outfilepath,sampleName):
	clipClusters=outfilepath+sampleName+'_threshold=%s_%s_allreads.mergedRT_CLIP_clusters'%(threshold_nr,index_tag)
	clust=pd.DataFrame(pd.read_table(clipClusters,header=None,skiprows=1))
	clust.columns=['chr','start','end','name','score','strand','m1','m2']
	clust['clusterSize']=clust['start']-clust['end']
	clust['clusterSize']=clust['clusterSize'].apply(lambda x: math.fabs(x))
	plt.boxplot(clust['clusterSize'])
	plt.tick_params(axis='x',labelbottom='off') 
	ax=plt.gca()
	for line in ax.get_xticklines():
		line.set_markersize(0)
	plt.ylabel('Cluster length (bases)',fontsize=5)
	locs,pltlabels = plt.yticks(fontsize=5)
	plt.title('Cluster size',fontsize=5)

def plot_clusterBindingIntensity(outfilepath,sampleName):
	clusterCenterHeatmap=outfilepath+sampleName+'_threshold=%s_%s_allreads.mergedRT_CLIP_clusters_cleaned_sorted.clusterCenter_heatmap.txt'%(threshold_nr,index_tag)
	hmap=pd.DataFrame(pd.read_table(clusterCenterHeatmap,header=None,skiprows=1))
	hmap_vals=hmap.ix[:,1:]
	sums=hmap_vals.sum(axis=1)
	hmap_vals=hmap_vals.loc[np.argsort(sums),:]
	plt.ylim(0,hmap_vals.shape[0])
	p=plt.pcolormesh(np.array(hmap_vals),cmap='Blues')
	plt.tick_params(axis='x',labelbottom='off') 
	plt.xlabel('Cluster position',fontsize=5)
	locs,pltlabels = plt.yticks(fontsize=5)
	plt.ylabel('Cluster number',fontsize=5)
	plt.title('Read distribution',fontsize=5)

def readUTRfile(path):
	geneCounts=pd.read_csv(path,header=None)
	geneCounts.columns=['Gene_name','Count']
	return geneCounts

def plot_readsBymRNAregion(outfilepath,sampleName): 
	fivePfile = outfilepath+'/PlotData_ReadsPerGene_5pUTR'
	threePfile = outfilepath+'/PlotData_ReadsPerGene_3pUTR'
	CDSfile = outfilepath+'/PlotData_ReadsPerGene_CDS'
	pc_5pReads = readUTRfile(fivePfile)['Count'].sum() if glob.glob(fivePfile) else 0
	pc_3pReads = readUTRfile(threePfile)['Count'].sum() if glob.glob(threePfile) else 0
	pc_CDSReads = readUTRfile(CDSfile)['Count'].sum() if glob.glob(CDSfile) else 0
	non_intronic=pc_5pReads+pc_3pReads+pc_CDSReads
	allProteinCoding=outfilepath +'clipGenes_proteinCoding_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved.bed'
	all_pc=pd.DataFrame(pd.read_table(allProteinCoding,header=None))
	pc_allReads=all_pc.shape[0]
	v=[float(pc_allReads-non_intronic)/pc_allReads,float(pc_5pReads)/pc_allReads,float(pc_CDSReads)/pc_allReads,float(pc_3pReads)/pc_allReads]
	pie_wedges=ax.pie(v,labels=["Intronic","5p UTR","CDS","3pUTR"],labeldistance=1.1,autopct='%1.1f%%')
	plt.rcParams['font.size']=5
	for wedge in pie_wedges[0]:
		wedge.set_edgecolor('black')
		wedge.set_lw(1)

fig1=plt.figure(1)

plt.subplot(2,3,1) 
plot_ReadAccounting(outfilepath,sampleName)
plt.subplot(2,3,2)
plot_ReadsPerCluster(outfilepath,sampleName)
plt.subplot(2,3,3)
plot_ClusterSizes(outfilepath,sampleName)
plt.subplot(2,3,4)
plot_clusterBindingIntensity(outfilepath,sampleName)
ax=plt.subplot(2,3,5)
plot_readsBymRNAregion(outfilepath,sampleName)
plt.subplot(2,3,6)
plot_BoundGeneTypes(outfilepath,sampleName)
fig1.tight_layout()

fig1.savefig(outfilepath+'Figure1.png',format='png',bbox_inches='tight',dpi=150,pad_inches=0.5)
#fig1.savefig(outfilepath+'Figure1.pdf',format='pdf',bbox_inches='tight',dpi=150,pad_inches=0.5)


def plot_mRNAgeneBodyDist(outfilepath,sampleName):
	averageGraph=outfilepath+'clipGenes_proteinCoding_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved_cleaned_sorted_UTRs_scaled_cds200_abt0_averageGraph.txt'
	hmap=pd.DataFrame(pd.read_table(averageGraph,header=None,skiprows=1))
	hmap=hmap.set_index(0)
	avgTrace=hmap.loc['treat',:]
	plt.plot(avgTrace,color='blue',linewidth='2')
	plt.vlines(200,0,np.max(avgTrace),linestyles='dashed')
	plt.vlines(400,0,np.max(avgTrace),linestyles='dashed')
	plt.ylim(0,np.max(avgTrace))
	plt.tick_params(axis='x',labelbottom='off') 
	plt.xlabel('mRNA gene body (5pUTR, CDS, 3pUTR)')
	plt.ylabel('Read density')
	plt.tick_params(axis='y',labelsize=5) 
	plt.title('CLIP signal across average mRNA transcript.',fontsize=5)

	
print "Making Figure 2"
logOpen.write("Making Figure 2\n")

def convertENBLids(enst_name):
	ensg_name=ensemblGeneAnnot.loc[enst_name,'name2']
	return ensg_name

def getUTRbindingProfile(utr,hmap_m):
	if utr=='5p':
		ix=(hmap_m[range(201,601)].sum(axis=1)==0)&(hmap_m[range(1,201)].sum(axis=1)>0)
		screen=readUTRfile(outfilepath+'/PlotData_ReadsPerGene_5pUTR')
	elif utr=='3p':
		ix=(hmap_m[range(1,401)].sum(axis=1)==0)&(hmap_m[range(401,601)].sum(axis=1)>0)
		screen=readUTRfile(outfilepath+'/PlotData_ReadsPerGene_3pUTR')
	elif utr=='5p3p':
		ix=(hmap_m[range(201,401)].sum(axis=1)==0)&(hmap_m[range(401,601)].sum(axis=1)>0)&(hmap_m[range(1,201)].sum(axis=1)>0)
		screen=readUTRfile(outfilepath+'/PlotData_ReadsPerGene_5p3pUTR')
	else:  # utr=='CDS'
		ix=(hmap_m[range(1,201)].sum(axis=1)==0)&(hmap_m[range(401,601)].sum(axis=1)==0)&(hmap_m[range(201,401)].sum(axis=1)>0)
		screen=readUTRfile(outfilepath+'/PlotData_ReadsPerGene_CDS')
		
	# Ensure all genes are also identified in pre-allocated gene lists.
	screen['Gene_name'] = screen['Gene_name'].map(lambda x: x.split('.')[0]) # remove transcript number from gene name
	hmap_m_utrSpec=hmap_m.ix[ix,:]
	hmap_m_utrSpec_filter=pd.merge(hmap_m_utrSpec,screen,left_on='ENSG_ID',right_on='Gene_name',how='inner')
	sums=hmap_m_utrSpec_filter[range(1,601)].sum(axis=1)
	hmap_m_utrSpec_filter=hmap_m_utrSpec_filter.loc[np.argsort(sums),:]
	return hmap_m_utrSpec_filter

def plot_geneBodyPartition(outfilepath,sampleName):
	treatMatrix=outfilepath+'clipGenes_proteinCoding_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved_cleaned_sorted_UTRs_scaled_cds200_abt0_treatmatrix.txt'
	hmap=pd.DataFrame(pd.read_table(treatMatrix,header=None,skiprows=1))
	
	# Ensure genes recovered from this analysis are independently identified using partitioning of CLIPper cluster data.
	hmap['ENSG_ID']=hmap.ix[:,0].apply(convertENBLids)
	bound_pc = outfilepath+'clipGenes_proteinCoding'
	pc_genes=pd.DataFrame(pd.read_table(bound_pc,header=None,))
	pc_genes.columns=['ENSG_ID']
	hmap_m=pd.merge(hmap,pc_genes,left_on='ENSG_ID',right_on='ENSG_ID',how='inner') 
	
	# Isolate intronic bound genes.
	tosave=outfilepath+'PlotData_ExclusiveBound_Intronic' 
	intronicBoundGenes=list(set(pc_genes['ENSG_ID'])-set(hmap_m['ENSG_ID']))
	np.savetxt(tosave,np.array(intronicBoundGenes),fmt="%s")
	
	# UTR specific genes.
	geneTypes=['5p','cds','3p','5p3p'] 
	depth=50
	for i in range(0,4):	
		if i == 0: name = "5pUTR"
		elif i == 1: name = "CDS"
		elif i == 2: name = "3pUTR"
		else: name = '5p3pUTR'
		fn = outfilepath+'/PlotData_ReadsPerGene_'+name
		if not glob.glob(fn): continue
		
		plt.subplot2grid((2,4),(1,i),colspan=1)
		utrMatrix=getUTRbindingProfile(geneTypes[i],hmap_m)
		tosave=outfilepath+'PlotData_ExclusiveBound_%s'%geneTypes[i] 
		np.savetxt(tosave,np.array(list(set(utrMatrix['ENSG_ID']))),fmt="%s")
		dataToPlot=utrMatrix[range(1,601)]
		
		if not dataToPlot.empty:
			p=plt.pcolormesh(np.array(dataToPlot)[-depth:-1,:],cmap='Blues')
			plt.title(geneTypes[i],fontsize=5)
			plt.vlines(200,0,depth,linestyles='dashed')
			plt.vlines(400,0,depth,linestyles='dashed')
			plt.tick_params(axis='x',labelbottom='off') 
			plt.tick_params(axis='y',labelleft='off') 
			plt.ylim(0,depth)
			plt.ylabel('Ranked genes (highest on bottom)',fontsize=5)
			plt.xticks(visible=False)
			plt.yticks(visible=False)
			plt.title('%s specific genes: %s'%(geneTypes[i],np.unique(utrMatrix['ENSG_ID']).shape[0]),fontsize=5)
	 
ensemblGeneAnnot=pd.DataFrame(pd.read_table(genesFile))
ensemblGeneAnnot=ensemblGeneAnnot.set_index('name') # Make ENST the index
plot_geneBodyPartition(outfilepath,sampleName)


fig2=plt.figure(2)
plt.subplot2grid((2,4),(0,0),colspan=4)
plot_mRNAgeneBodyDist(outfilepath,sampleName)
plot_geneBodyPartition(outfilepath,sampleName)
fig2.tight_layout()
fig2.savefig(outfilepath+'Figure2.png',format='png',bbox_inches='tight',dpi=150,pad_inches=0.5)
fig2.savefig(outfilepath+'Figure2.pdf',format='pdf',bbox_inches='tight',dpi=150,pad_inches=0.5)


def read_csv_by_line(fn):
	import csv
	
	RTpositions = []
	start = 0
	end = 0
	with open(fn, 'r') as ifile:
		reader = csv.reader(ifile)
		reader.next()
		for row in reader:
			RTpositions.append(int(row[7]))
			
		ifile.seek(0)
		reader.next()  # skip header
		row = reader.next()
		start = int(row[9])
		end = int(row[8])
	return np.array(RTpositions), start, end
	

def plot_repeatRNA(outfilepath,sampleName):
	repeat_genome=np.genfromtxt(repeatGenomeBuild,dtype='string')
	repeat_genome_bases=repeat_genome[1]
	
	repFiles=glob.glob(outfilepath + '/PlotData_RepeatRNAreads_*')
	
	plotDim=math.ceil(math.sqrt(len(repFiles)))
	i=0
	for path in repFiles:
		name=path.split('RepeatRNAreads_')[-1]
		try:
			(RTpositions, start, end) = read_csv_by_line(path)
			
			# Histogram of RT stops across gene body
			bins=range(start,end+2,1)
			hist,bins=np.histogram(RTpositions,bins=bins)
			width=0.7*(bins[1]-bins[0])
			center=(bins[:-1] + bins[1:])/2
			# Normalize
			histPlot=np.array(hist,dtype=float)
			histPlot=np.array(histPlot/float(len(RTpositions)),dtype=float)
				
			# Make sure same length
			sequence=repeat_genome_bases[start:end+1]
			hist = hist[:len(sequence)]
			histPlot = hist[:len(sequence)]
			center = center[:len(sequence)]
			
			# Subplot
			plt.subplot(plotDim,plotDim,i+1)
			plt.bar(center,histPlot,align='center',width=width,color='blue',alpha=0.45)
			plt.tick_params(axis='x',labelsize=2.5) 
			plt.tick_params(axis='y',labelsize=2.5)  
			plt.title('RT stops for %s: %s'%(name,len(RTpositions)),fontsize=5)
			plt.xlim(start,end)  
			# Record data
			storageDF=pd.DataFrame()
			storageDF['Sequence']=pd.Series(list(sequence))
			readsPerBase=np.array(list(hist))
			readsPerBaseNorm=np.array(list(histPlot))
			storageDF['RT_stops']=readsPerBase
			storageDF['RT_stops_norm']=readsPerBaseNorm			  
			outfilepathToSave=outfilepath +'/PlotData_RepeatRNAHist_%s'%name
			storageDF.to_csv(outfilepathToSave)
			i+=1
		except:
			print "No reads for repeatRNA %s"%name			  
	plt.tight_layout()

	
print "Making Figure 3"
logOpen.write("Making Figure 3\n")
fig3=plt.figure(3)
plot_repeatRNA(outfilepath,sampleName)
fig3.tight_layout()
fig3.savefig(outfilepath+'Figure3.png',format='png',bbox_inches='tight',dpi=150,pad_inches=0.5)
fig3.savefig(outfilepath+'Figure3.pdf',format='pdf',bbox_inches='tight',dpi=150,pad_inches=0.5)

def plot_rDNA(outfilepath,sampleName):
	plt.subplot2grid((3,3),(0,0),colspan=3)
	name='rDNA'
	rDNA=glob.glob(outfilepath + 'PlotData_RepeatRNAreads_rDNA')
	# hits_per_rep=pd.read_csv(rDNA[0])
	# RTpositions=hits_per_rep['RT_stop']
	# start=hits_per_rep.loc[0,'Repeat_Start']
	# end=hits_per_rep.loc[0,'Repeat_End']
	
	(RTpositions, start, end) = read_csv_by_line(rDNA[0])

	bins=range(start,end+2,1)
	hist,bins=np.histogram(RTpositions,bins=bins)
	width=0.7*(bins[1]-bins[0])
	center=(bins[:-1]+bins[1:])/2
	histPlot=np.array(hist,dtype=float)
	histPlot=np.array(histPlot/float(len(RTpositions)),dtype=float)
	plt.bar(center,histPlot,align='center',width=width,color='blue',alpha=0.45)
	plt.tick_params(axis='x',labelsize=2.5) 
	plt.tick_params(axis='y',labelsize=2.5)  
	plt.title('RT stops for %s: %s'%(name,len(RTpositions)),fontsize=5)
	plt.xlim(start,end)	   
	
	# Features of rDNA with respect to start of the bowtie index (index=0)
	rRNAstart=start
	plt.axvspan(start18s+rRNAstart,end18s+rRNAstart,facecolor='g',alpha=0.5)
	plt.axvspan(start5s+rRNAstart,end5s+rRNAstart,facecolor='r',alpha=0.5)
	plt.axvspan(start28s+rRNAstart,end28s+rRNAstart,facecolor='b',alpha=0.5)
	
	# Generate histogram for transcribed region
	plt.subplot2grid((3,3),(1,0),colspan=3)
	datarDNAOnly=RTpositions-start
	bins=range((start-start),(end-start+2),1)
	hist,bins=np.histogram(datarDNAOnly,bins=bins)
	width=0.7*(bins[1]-bins[0])
	center=(bins[:-1] + bins[1:])/2
	histPlot=np.array(hist,dtype=float)
	histPlot=np.array(histPlot/float(len(RTpositions)),dtype=float)
	plt.bar(center,histPlot,align='center',width=width,color='blue',alpha=0.45)
	plt.tick_params(axis='x',labelsize=2.5) 
	plt.tick_params(axis='y',labelsize=2.5)  
	plt.xlabel('rRNA locus position (bin=1 base)',fontsize=5)
	plt.ylabel('Normalized RT stop / bin',fontsize=2.5)
	plt.axvspan(start18s,end18s,facecolor='g',alpha=0.5)
	plt.axvspan(start5s,end5s,facecolor='r',alpha=0.5)
	plt.axvspan(start28s,end28s,facecolor='b',alpha=0.5)
	plt.xlim(0,rRNAend)
	
	# Individual regions 
	plt.subplot2grid((3,3),(2,0),colspan=1)
	plt.bar(center,histPlot,align='center',width=width,color='green',alpha=0.75)
	plt.xlim(start18s,end18s)
	plt.xlabel('rRNA locus position (bin=1 base)',fontsize=5)
	plt.ylabel('Normalized RT stop / bin',fontsize=2.5)
	plt.tick_params(axis='x',labelsize=5) 
	plt.tick_params(axis='y',labelsize=5) 
	plt.title('18s Region',fontsize=5)
	plt.subplot2grid((3,3),(2,1),colspan=1)
	plt.bar(center,histPlot,align='center',width=width,color='red',alpha=0.75)
	plt.xlim(start5s,end5s)
	plt.xlabel('rRNA locus position (bin=1 base)',fontsize=5)
	plt.tick_params(axis='x',labelsize=5) 
	plt.tick_params(axis='y',labelsize=5) 
	plt.title('5.8s Region',fontsize=5)
	plt.subplot2grid((3,3),(2,2),colspan=1)
	plt.bar(center,histPlot,align='center',width=width,color='blue',alpha=0.75)
	plt.xlim(start28s,end28s)
	plt.xlabel('rRNA locus position (bin=1 base)',fontsize=5)
	plt.tick_params(axis='x',labelsize=5) 
	plt.tick_params(axis='y',labelsize=5)  
	plt.title('28s Region',fontsize=5)
	plt.tight_layout()

print "Making Figure 4"
logOpen.write("Making Figure 4\n")
fig4=plt.figure(4)
plot_rDNA(outfilepath,sampleName)
fig4.tight_layout()
fig4.savefig(outfilepath+'Figure4.png',format='png',bbox_inches='tight',dpi=150,pad_inches=0.5)
fig4.savefig(outfilepath+'Figure4.pdf',format='pdf',bbox_inches='tight',dpi=150,pad_inches=0.5)


def getBindingFrac(type_specific):
	# 5' position on the negative strand is snoRNA stop coordinate.
	neg_data=type_specific[type_specific['strand_snoRNA']=='-']
	neg_data['diff']=np.abs(neg_data['Stop_snoRNA']-neg_data['Start']) 
	neg_data['frac']=neg_data['diff']/(neg_data['Stop_snoRNA']-neg_data['Start_snoRNA'])
	# 5' position on the positive strand is snoRNA start coordinate.
	pos_data=type_specific[type_specific['strand_snoRNA']=='+']
	pos_data['diff']=np.abs(pos_data['Start_snoRNA']-pos_data['Start'])
	pos_data['frac']=pos_data['diff']/(pos_data['Stop_snoRNA']-pos_data['Start_snoRNA'])
	DF_snoProfile=pd.concat([neg_data,pos_data])
	return DF_snoProfile

	
print "Making Figure 5"
logOpen.write("Making Figure 5\n")
print "snoRNA gene body analysis."
logOpen.write("snoRNA gene body analysis.\n")
snorna_file = outfilepath+"clipGenes_snoRNA_LowFDRreads.bed"

if os.stat(snorna_file).st_size > 0:
	bf_sno=pd.read_table(snorna_file,header=None)
	bf_sno.columns=['Chr','Start','End','CLIPper_name','Q','Strand','Chr_snoRNA','Start_snoRNA','Stop_snoRNA','name_snoRNA','Type','strand_snoRNA']
	snoTypes=pd.DataFrame(bf_sno.groupby('Type').size())
	snoTypes.columns=['Reads']
	snoTypes['Fraction']=snoTypes['Reads']/sum(snoTypes['Reads'])
	outfilepathToSave=outfilepath+'/PlotData_readsPerSnoRNAType'
	snoTypes.to_csv(outfilepathToSave)

	snoTypesAndGenes=pd.DataFrame(bf_sno.groupby(['Type','name_snoRNA']).size())
	snoTypesAndGenes.columns=['Count_per_gene']
	outfilepathToSave=outfilepath+'/PlotData_geneStatsPerSnoRNAType'
	snoTypesAndGenes.to_csv(outfilepathToSave)
		  
	fig5=plt.figure(5)
	ax=plt.subplot(2,2,1)
	pie_wedges=ax.pie(snoTypes['Fraction'],labels=snoTypes.index,labeldistance=1.1,autopct='%1.1f%%')
	plt.rcParams['font.size']=5
	for wedge in pie_wedges[0]:
		wedge.set_edgecolor('black')
		wedge.set_lw(1)

	i=2
	for sType in set(bf_sno['Type']):
		type_specific=bf_sno[bf_sno['Type']==sType]
		sno_profile=getBindingFrac(type_specific)
		
		if sType=='C':
			title="C/D_box"
		elif sType=='H':
			title="H/ACA_box"
		else:
			title="scaRNA"
		
		outfilepathToSave=outfilepath+'/PlotData_snoRNAReadDist_%s'%sType
		sno_profile.to_csv(outfilepathToSave)
		
		plt.subplot(2,2,i)
		bins=np.arange(0,1,0.01)
		hist,bins=np.histogram(sno_profile['frac'],bins=bins)
		hist=np.array(hist/float(sno_profile['frac'].shape[0]),dtype=float)
		width=0.7*(bins[1]-bins[0])
		center=(bins[:-1] + bins[1:])/2
		plt.bar(center,hist,align='center',width=width,color='blue',alpha=0.75)
		plt.tick_params(axis='x',labelsize=5) 
		plt.tick_params(axis='y',labelsize=5)  
		plt.xlabel('Fraction of gene body (5p - 3p)',fontsize=5)
		plt.title('Binding profile for %s'%title,fontsize=5)
		i+=1

	fig5.tight_layout()
	fig5.savefig(outfilepath+'Figure5.png',format='png',bbox_inches='tight',dpi=150,pad_inches=0.5)
	fig5.savefig(outfilepath+'Figure5.pdf',format='pdf',bbox_inches='tight',dpi=150,pad_inches=0.5)


def getncRNABindingFrac(type_specific):
	# 5' position on the negative strand is snoRNA stop coordinate.
	neg_data=type_specific[type_specific['Strand']=='-']
	neg_data['diff']=np.abs(neg_data['Gene End (bp)']-neg_data['RT_stop']) 
	neg_data['frac']=neg_data['diff']/(neg_data['Gene End (bp)']-neg_data['Gene Start (bp)'])
	# 5' position on the positive strand is snoRNA start coordinate.
	pos_data=type_specific[type_specific['Strand']=='+']
	pos_data['diff']=np.abs(pos_data['Gene Start (bp)']-pos_data['RT_stop'])
	pos_data['frac']=pos_data['diff']/(pos_data['Gene End (bp)']-pos_data['Gene Start (bp)'])
	DF_ncRNAProfile=pd.concat([neg_data,pos_data])
	return DF_ncRNAProfile

	
print "Making Figure 6"
logOpen.write("Making Figure 6\n")
print "ncRNA gene body analysis."
st_stopFiles=glob.glob(outfilepath+"*.geneStartStop")
st_stopFiles=[f for f in st_stopFiles if 'rRNA' not in f]
fig6=plt.figure(6)
plotDim=math.ceil(math.sqrt(len(st_stopFiles)))
i=1
for st_file in st_stopFiles:
	name=st_file.split('clipGenes_')[1].split('_LowFDRreads')[0]
	tmp=pd.read_csv(st_file)
	tmp['RT_stop']=tmp['Start']+expand
	tmp_profile=getncRNABindingFrac(tmp)
	plt.subplot(plotDim,plotDim,i)
	bins=np.arange(0,1,0.01)
	hist,bins=np.histogram(tmp_profile['frac'],bins=bins)
	hist=np.array(hist/float(tmp_profile['frac'].shape[0]),dtype=float)
	width=0.7*(bins[1]-bins[0])
	center=(bins[:-1] + bins[1:])/2
	plt.bar(center,hist,align='center',width=width,color='blue',alpha=0.75)
	plt.tick_params(axis='x',labelsize=5) 
	plt.tick_params(axis='y',labelsize=5)  
	plt.xlabel('Fraction of gene body (5p - 3p)',fontsize=5)
	plt.title('Binding profile for %s'%name,fontsize=5)
	i+=1
fig6.tight_layout()
fig6.savefig(outfilepath+'Figure6.png',format='png',bbox_inches='tight',dpi=150,pad_inches=0.5)
fig6.savefig(outfilepath+'Figure6.pdf',format='pdf',bbox_inches='tight',dpi=150,pad_inches=0.5)


# Removing things
os.chdir(outfilepath)
os.system("mkdir rawdata")
os.system("mv PlotData_* rawdata")
os.system("mv clipGenes_proteinCoding rawdata")
os.system("mv *_allreads.mergedRT_CLIP_clusters_lowFDRreads_cleaned_sorted* rawdata")
os.system("mv *_allreads.mergedRT_CLIP_clusters_lowFDRreads_centerCoord_cleaned_sorted* rawdata")
os.system("mv *_allreads.mergedRT.bed rawdata")
os.system("mv clipGenes_proteinCoding_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved_cleaned_sorted_UTRs_scaled_cds200_abt0_*.txt rawdata")
os.system("mv clipGenes_proteinCoding_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved* rawdata")
os.system("mv *.mergedRT_CLIP_clusters.bed rawdata")
os.system("mv *_withDupes_noBlacklist_noRepeat.bed rawdata")
os.system("mv *_withDupes.bed rawdata")
os.system("mv *threshold*mergedRT_CLIP_clusters_cleaned.bed rawdata")
os.system("mv runLog *stats* *.bam rawdata")

os.system("mkdir figures")
os.system("mv Figure* figures")

os.system("mkdir todelete")
os.system("mv *.* todelete")
os.system("mv clipGenes_* todelete")

logOpen.close()



